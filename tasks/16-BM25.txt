Here is the implementation plan for **Claude Code** to integrate **BM25/Keyword Scoring**.

This requires changes to the worker pipeline because currently, the worker receives the *vector embedding* of the query, but not the *text* of the query itself. BM25 needs the raw text to count word overlaps.

### Phase 1: Pipeline Plumbing (`src/retrieval/scoring.js` & `src/retrieval/worker.js`)

**Context:** We need to pass the user's search text down to the worker so it can perform string matching.

**Prompt for Claude Code:**
```text
I need to pass the raw query text to the scoring worker.

1.  Read `src/retrieval/scoring.js`.
    In `selectRelevantMemoriesSimple`, find where `runWorkerScoring` is called.
    Pass `userMessages` (the variable holding the text used for embedding) into the `runWorkerScoring` function as a new argument named `queryText`.

2.  Update `runWorkerScoring` definition to accept `queryText`.
    Include `queryText` in the `worker.postMessage` payload object.

3.  Read `src/retrieval/worker.js`.
    Update the `onmessage` destructuring to extract `queryText` from `e.data`.
    Pass `queryText` as a new argument into the `scoreMemories` function call.
```

### Phase 2: The Math Engine (`src/retrieval/math.js`)

**Context:** We need to implement the BM25 algorithm. This involves tokenizing text, calculating "Inverse Document Frequency" (IDF) across all memories, and then scoring specific overlaps.

**Prompt for Claude Code:**
```text
I need to implement BM25 logic in `src/retrieval/math.js`.

1.  Create a helper function `tokenize(text)`:
    - Return an array of lowercase words (regex `/\w+/g`).
    - Filter out common stop words (e.g., "the", "and", "is", "a", "an", "in", "to").

2.  Create a helper function `calculateIDF(memories)`:
    - Iterate all memories.
    - Count how many memories contain each unique term.
    - Return a Map of term -> IDF score using standard BM25 IDF formula.
    - Calculate and return `avgDL` (average document length) as well.

3.  Create a helper `bm25Score(queryTokens, memoryTokens, idfMap, avgDL)`:
    - Constants: k1 = 1.2, b = 0.75.
    - Calculate score based on term frequency in the memory vs global IDF.

4.  Update the `scoreMemories` function signature to accept `queryText`.

5.  Inside `scoreMemories`:
    - If `queryText` is present:
        - Call `tokenize(queryText)`.
        - Call `calculateIDF(memories)`.
        - Pre-tokenize all memory summaries to avoid re-doing it inside the loop.
    - Inside the scoring loop, calculate the BM25 score.
    - Add the BM25 score to the total score.
    - Apply a weighting factor (use `settings.keywordMatchWeight` or default to 1.0).
```

### Phase 3: Settings & Configuration (`src/ui/settings.js` & `src/constants.js`)

**Context:** The user needs to be able to tune how much "Keywords" matter versus "Semantic Vector" matching.

**Prompt for Claude Code:**
```text
I need to add a setting for Keyword Match Weight.

1.  Read `src/constants.js`.
    Add `keywordMatchWeight: 1.0` to `defaultSettings`.

2.  Read `src/ui/settings.js`.
    In `bindUIElements`, add a bind for a new slider `openvault_keyword_weight`.
    It should map to `settings.keywordMatchWeight`.

3.  Read `templates/settings_panel.html`.
    In the "Pipeline Tuning" group add a new slider for "Keyword Match Weight".
    Range: 0 to 10. Step: 0.1. Default: 1.0.

4.  Read `src/retrieval/scoring.js`.
    In `runWorkerScoring`, ensure `settings.keywordMatchWeight` is passed in the `settings` object sent to the worker.
```

### Phase 4: Integration Verification (`src/retrieval/math.js`)

**Context:** We need to ensure the new score is actually being added to the final result in the calculation function.

**Prompt for Claude Code:**
```text
Refine `src/retrieval/math.js`.

In `calculateScore`:
1.  Ensure the function signature accepts the computed `bm25Score`.
2.  Add `bm25Score * settings.keywordMatchWeight` to the final `score` variable.
3.  Ensure that even if `contextEmbedding` (vectors) is missing, BM25 still runs if `queryText` is available.
```

### Verification Plan

1.  **Settings:** Open settings, verify "Keyword Match Weight" slider exists. Set it to a high value (e.g., 5.0).
2.  **Test:** Create a memory with a specific nonsense word like "Zorbazoid".
3.  **Chat:** Send a message "Tell me about the Zorbazoid".
4.  **Debug:** Check the logs (enable Debug Mode). You should see the memory with "Zorbazoid" ranking very high because of the exact keyword match, even if the semantic embedding model doesn't know what a Zorbazoid is.

---

