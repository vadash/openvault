# Design: BM25 Scoring Fix + Asymmetric Embedding Prompts

## 1. Problem Statement

After adding Snowball stemming to BM25 tokenization, three scoring pathologies emerged:

1. **BM25 explosion**: One memory scored 54.2 total (44.8 from BM25 alone) ‚Äî a 30√ó outlier over other BM25 contributions. BM25 is unbounded and can dominate vector similarity.
2. **Entity boost √ó stemming TF inflation**: `Suzy` (stemmed to `suzi`) is entity-boosted 17√ó in the query, but appears in nearly every memory. High query TF √ó low-but-nonzero IDF √ó short-doc length normalization = score blowup.
3. **Post-stem runts**: `–±–æ—é—Å—å` (5 chars) passes length filter, then Snowball stems it to `–±–æ` (2 chars). No second filter catches this.

### Additional Problem: Symmetric Prompting Hurts Quality

Benchmark testing (`tests/prompt-comparison.html`) revealed that:
- **Symmetric prompting** (same prefix for query and document) causes vector collapse and negative separation
- **EmbeddingGemma-300M is an asymmetric model** ‚Äî it expects different formats for queries vs documents
- Baseline (no prompt) outperformed symmetric prompts because it didn't force identical prefixes

## 2. Goals & Non-Goals

### Must do
- BM25 can never dominate vector similarity in the final score
- Entity boost scales down for corpus-common names
- Post-stemming tokens below 3 chars are filtered
- Use **asymmetric** embedding prompts (different prefixes for query vs document)
- Tags come from **LLM extraction**, not regex

### Won't do
- Replace Snowball with spaCy/POS-based lemmatization (too heavy for client-side JS)
- Redesign entity extraction logic
- Build a separate regex-based auto-tagger (brittle, duplicates LLM understanding)

## 3. Proposed Architecture

### 3a. Alpha-Blend Scoring (unchanged)

**Current** (additive, unbounded):
```
score = base + vectorSim √ó 15 + bm25 √ó 3
```

**Proposed** (normalized alpha-blend):
```
score = base + alpha √ó normalizedVector + (1 - alpha) √ó normalizedBM25
```

Where:
- `alpha = 0.7` (default, user-configurable)
- `normalizedVector` = existing `(sim - threshold) / (1 - threshold)` scaled to `[0, 1]`, then √ó `combinedBoostWeight`
- `normalizedBM25` = `bm25 / maxBM25` across current batch, scaled to `[0, 1]`, then √ó `combinedBoostWeight`
- `combinedBoostWeight` replaces both `vectorSimilarityWeight` and `keywordMatchWeight` ‚Äî single knob controlling total boost budget (default: `15`)

### 3b. IDF-Aware Entity Boost (unchanged)

Scale entity boost repeats inversely by document frequency to prevent corpus-common names from dominating.

### 3c. Post-Stem Length Filter (unchanged)

Filter tokens below 3 chars after stemming.

### 3d. Asymmetric Embedding Prompts

**Benchmark Results** (from `tests/prompt-comparison.html`):

| Prompt Type | Separation | Precision@5 | AUC | Overall |
|-------------|------------|-------------|-----|---------|
| Baseline (none) | +0.0189 | 0.70 | 0.582 | 0.594 |
| Symmetric: Action | -0.0025 | 0.56 | 0.408 | 0.326 |
| üî• Asymmetric: Intent-Tagged | +0.0079 | 0.60 | **0.603** | **0.614** |

**Winner**: `Asymmetric: Intent-Tagged` with LLM-generated categorical tags.

#### Proposed Asymmetric Prompts

**Query side** (applied at retrieval time):
```
search for similar scenes: {user_input}
```

**Document side** (applied at memory save time, with LLM-generated tags):
```
[{TAG1}] [{TAG2}] {memory_summary}
```

#### Tags: Generated by LLM During Extraction

Instead of regex-based tagging, the extraction LLM assigns tags as part of its analysis. This leverages the LLM's understanding of context, nuance, and multilingual content.

**Available tags** (assigned by LLM):

| Tag | Description |
|-----|-------------|
| `EXPLICIT` | Sexual acts, orgasms, anatomy (–º–∏–Ω–µ—Ç, –∫—É–Ω–Ω–∏–ª–∏–Ω–≥—É—Å, —Ç—Ä–∞—Ö–∞—Ç—å—Å—è, –æ—Ä–≥–∞–∑–º, —Å–ø–µ—Ä–º–∞) |
| `BDSM` | Power exchange, bondage, pain, dominance/submission (–≤–µ—Ä—ë–≤–∫–∞, —Å—Ç–æ–ø-—Å–ª–æ–≤–æ, —à–ª—ë–ø–∞—Ç—å, –ø—Ä–∏–∫–∞–∑) |
| `DOMESTIC` | Daily life, routine activities (–º–∞–≥–∞–∑–∏–Ω, –∫—É—Ö–Ω—è, —Å–æ–Ω, –ø—Ä–æ–≥—É–ª–∫–∞, –ø–æ–∫—É–ø–∫–∞, —É–∂–∏–Ω) |
| `LORE` | Backstory, trauma, family history, secrets (–¥–µ—Ç—Å—Ç–≤–æ, —Å—Ç—Ä–∞—Ö, –Ω–∏—â–µ—Ç–∞, —Ä–æ–¥–∏—Ç–µ–ª–∏) |
| `ROMANCE` | Affection without explicit sex (–æ–±—ä—è—Ç–∏—è, –ø–æ—Ü–µ–ª—É–π, –¥–µ—Ä–∂–∞—Ç—å—Å—è –∑–∞ —Ä—É–∫–∏, —Å–≤–∏–¥–∞–Ω–∏–µ) |
| `COMBAT` | Fighting, violence, injury (–±–∏—Ç–≤–∞, —É–¥–∞—Ä, –∫—Ä–æ–≤—å, —Ä–∞–Ω–∞, –∞—Ç–∞–∫–æ–≤–∞—Ç—å) |
| `MYSTERY` | Investigations, puzzles, unknown elements |
| `NONE` | Default fallback when nothing else applies |

**Multiple tags allowed**: A memory can have `["BDSM", "EXPLICIT"]` if it contains both power dynamics and sexual acts.

## 4. Data Models / Schema

### Settings Changes

```js
// Asymmetric embedding prompts:
embeddingQueryPrefix: 'search for similar scenes: ',  // Applied during retrieval
embeddingTagFormat: 'bracket',                        // Format: 'bracket' = [TAG], 'none' = disable

// Replace vectorSimilarityWeight + keywordMatchWeight with:
alpha: 0.7,                    // vector vs BM25 blend ratio
combinedBoostWeight: 15,       // total boost budget for vector+BM25

// Keep existing:
entityBoostWeight: 5.0,        // base entity boost (now IDF-modulated)
vectorSimilarityThreshold: 0.5 // unchanged
```

### Memory Schema Addition

```js
{
    // ... existing fields: summary, event_type, importance, etc ...
    tags: ['EXPLICIT', 'BDSM'],  // NEW: Assigned by LLM during extraction
    embedding: [0.234, -0.123, ...],
    embedding_tags: ['EXPLICIT', 'BDSM'],  // Track what tags were embedded (for re-embed)
}
```

### Extraction Zod Schema Update

```js
const memoryEventSchema = z.object({
    event_type: z.enum(['action', 'revelation', 'emotion_shift', 'relationship_change']),
    summary: z.string().min(8).max(200),
    importance: z.number().int().min(1).max(5),
    characters_involved: z.array(z.string()),
    witnesses: z.array(z.string()),
    location: z.string().nullable(),
    is_secret: z.boolean(),
    emotional_impact: z.record(z.string()),
    relationship_impact: z.record(z.string()),

    // NEW: Category tags for embedding separation
    tags: z.array(z.enum([
        'EXPLICIT', 'BDSM', 'DOMESTIC', 'LORE',
        'ROMANCE', 'COMBAT', 'MYSTERY', 'NONE'
    ])).default(['NONE'])
});
```

## 5. LLM Prompt Changes

### 5a. Add `<tags_field>` Directive to Extraction Prompt

Insert after `<importance_scale>` section in `src/prompts.js`:

```
<tags_field>
After writing each event's summary, assign 1-3 category tags that BEST describe the content.

Available tags:
- EXPLICIT: Sexual acts (–º–∏–Ω–µ—Ç, –∫—É–Ω–Ω–∏–ª–∏–Ω–≥—É—Å, —Ç—Ä–∞—Ö–∞—Ç—å—Å—è, –æ—Ä–≥–∞–∑–º, —Å–ø–µ—Ä–º–∞, –ø—Ä–æ–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–µ, Blowjob, „Éï„Çß„É©„ÉÅ„Ç™)
- BDSM: Power exchange, bondage, pain play, dominance/submission (–≤–µ—Ä—ë–≤–∫–∞, —Å—Ç–æ–ø-—Å–ª–æ–≤–æ, —à–ª—ë–ø–∞—Ç—å, –ø—Ä–∏–∫–∞–∑, bond, Á∏õ„Çä)
- DOMESTIC: Daily life activities (–º–∞–≥–∞–∑–∏–Ω, –∫—É—Ö–Ω—è, —Å–æ–Ω, –ø—Ä–æ–≥—É–ª–∫–∞, –ø–æ–∫—É–ø–∫–∞, —É–∂–∏–Ω, shopping, Ë≤∑„ÅÑÁâ©)
- LORE: Character backstory, trauma, family history, secrets (–¥–µ—Ç—Å—Ç–≤–æ, —Å—Ç—Ä–∞—Ö, –Ω–∏—â–µ—Ç–∞, —Ä–æ–¥–∏—Ç–µ–ª–∏, childhood, ÂπºÂ∞ëÊúü)
- ROMANCE: Affection without explicit sex (–æ–±—ä—è—Ç–∏—è, –ø–æ—Ü–µ–ª—É–π, –¥–µ—Ä–∂–∞—Ç—å—Å—è –∑–∞ —Ä—É–∫–∏, —Å–≤–∏–¥–∞–Ω–∏–µ, hug, ÊãÖ„ÅÑ„Å†Êâã)
- COMBAT: Fighting, violence, injury (–±–∏—Ç–≤–∞, —É–¥–∞—Ä, –∫—Ä–æ–≤—å, —Ä–∞–Ω–∞, –∞—Ç–∞–∫–æ–≤–∞—Ç—å, battle, Êà¶„ÅÑ)
- MYSTERY: Investigations, puzzles, unknown elements
- NONE: Default if nothing else applies

Examples:
- "Suzy —Å–¥–µ–ª–∞–ª–∞ –º–∏–Ω–µ—Ç" ‚Üí tags: ["EXPLICIT"]
- "–°–≤—è–∑–∞–ª –µ—ë –≤–µ—Ä—ë–≤–∫–æ–π" ‚Üí tags: ["BDSM"]
- "–ü–æ—à–ª–∏ –≤ –º–∞–≥–∞–∑–∏–Ω –∑–∞ –±–µ–ª—å—ë–º" ‚Üí tags: ["DOMESTIC"]
- "–†–∞—Å—Å–∫–∞–∑–∞–ª–∞ –æ –¥–µ—Ç—Å—Ç–≤–µ –≤ –Ω–∏—â–µ—Ç–µ" ‚Üí tags: ["LORE"]
- "–ü–æ—Ü–µ–ª–æ–≤–∞–ª –µ—ë —â—ë–∫—É" ‚Üí tags: ["ROMANCE"]
- "–°–≤—è–∑–∞–ª –∏ –∑–∞—Å—Ç–∞–≤–∏–ª —Å–æ—Å–∞—Ç—å" ‚Üí tags: ["BDSM", "EXPLICIT"]

Apply tags to help with semantic retrieval. Multiple tags allowed when content overlaps.
</tags_field>
```

### 5b. Update All Examples to Include Tags

Every example output in the extraction prompt must include the `tags` field:

```js
<example type="action_intimate" lang="RU">
Output:
{
  "reasoning": "–ü–µ—Ä–≤—ã–π —Å–µ–∫—Å—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–∞–∫—Ç –º–µ–∂–¥—É –°–∞—à–µ–π –∏ –í–æ–≤–æ–π...",
  "events": [{
    "event_type": "action",
    "summary": "–°–∞—à–∞ –ø–æ–≤–∞–ª–∏–ª–∞ –í–æ–≤—É –Ω–∞ –∫—Ä–æ–≤–∞—Ç—å, –ø—Ä–∏–∂–∞–ª–∞ –∑–∞–ø—è—Å—Ç—å—è –∏ –Ω–∞—á–∞–ª–∞ —Ç–µ—Ä–µ—Ç—å—Å—è...",
    "importance": 4,
    "characters_involved": ["–°–∞—à–∞", "–í–æ–≤–∞"],
    "witnesses": [],
    "location": null,
    "is_secret": false,
    "emotional_impact": {"–°–∞—à–∞": "–≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ, –≤–ª–∞—Å—Ç—å"},
    "relationship_impact": {"–°–∞—à–∞->–í–æ–≤–∞": "—Ñ–∏–∑–∏—á–µ—Å–∫–∞—è –±–ª–∏–∑–æ—Å—Ç—å –Ω–∞—á–∞–ª–∞—Å—å"},
    "tags": ["EXPLICIT"]  // ‚Üê ADD THIS LINE TO ALL EXAMPLES
  }]
}
</example>
```

## 6. Implementation Flow

### 6a. Memory Creation (with Tags)

```
User sends messages
       ‚Üì
LLM Extraction (prompts.js)
  - Analyzes content
  - Assigns event_type, importance
  - Assigns tags ‚Üê NEW
       ‚Üì
Format for embedding
  - tags: ["EXPLICIT", "BDSM"]
  - embedText: "[EXPLICIT] [BDSM] {summary}"
       ‚Üì
Generate embedding
  - strategy.getDocumentEmbedding(embedText)
       ‚Üì
Save to storage
  {
    summary,
    tags,              // Store raw tags
    embedding,
    embedding_tags,    // Track what was embedded
    ...other fields
  }
```

### 6b. Retrieval (with Query Prefix)

```
User queries: "–Ø –∂–∞–¥–Ω–æ –±–µ—Ä—É –µ–µ —Ç–∏—Ç–µ—á–∫—É..."
       ‚Üì
Format query
  - queryText: "search for similar scenes: –Ø –∂–∞–¥–Ω–æ –±–µ—Ä—É –µ–µ —Ç–∏—Ç–µ—á–∫—É..."
       ‚Üì
Generate query embedding
  - strategy.getQueryEmbedding(queryText)
       ‚Üì
Score all memories
  - Cosine similarity
  - BM25 + alpha-blend
       ‚Üì
Return top N
```

### 6c. Update `TransformersStrategy`

```javascript
class TransformersStrategy extends EmbeddingStrategy {
    async getEmbedding(text, type = 'query') {
        // type: 'query' or 'doc'
        const settings = getDeps().getExtensionSettings()[extensionName];

        let prefix = '';
        if (type === 'query') {
            // Query side: always use prefix
            prefix = settings?.embeddingQueryPrefix ?? 'search for similar scenes: ';
        } else {
            // Document side: no prefix (tags handle this)
            prefix = settings?.embeddingDocPrefix ?? '';
        }

        const input = prefix + text.trim();
        const output = await this.#loadPipeline(this.#currentModelKey)
            .then(pipe => pipe(input, { pooling: 'mean', normalize: true }));
        return Array.from(output.data);
    }

    async getQueryEmbedding(text) {
        return this.getEmbedding(text, 'query');
    }

    async getDocumentEmbedding(text) {
        return this.getEmbedding(text, 'doc');
    }
}
```

### 6d. Tag Formatting Before Embedding

Where memories are saved (after LLM extraction):

```javascript
async function createMemoryFromExtraction(extractedEvent) {
    const { summary, tags, ...rest } = extractedEvent;

    // Format tags for embedding: "[EXPLICIT] [BDSM] {summary}"
    const tagPrefix = tags
        .filter(t => t !== 'NONE')
        .map(t => `[${t}]`)
        .join(' ');

    const embedText = tagPrefix ? `${tagPrefix} ${summary}` : summary;

    // Generate embedding
    const embedding = await strategy.getDocumentEmbedding(embedText);

    return {
        ...rest,
        summary,
        tags,                    // Store raw tags from LLM
        embedding,
        embedding_tags: tags     // Track what was embedded (for re-embed)
    };
}
```

## 7. Migration Path

### Phase 1: Update Extraction Prompt
- Add `<tags_field>` directive to `src/prompts.js`
- Add `tags` field to Zod schema
- Update all examples to include `tags`

### Phase 2: Update Embedding Strategy
- Add `getQueryEmbedding()` and `getDocumentEmbedding()` methods
- Add `embeddingQueryPrefix` setting

### Phase 3: Update Memory Creation Flow
- Read `tags` from LLM response
- Format `[TAG]` prefix before embedding
- Store `tags` and `embedding_tags` in memory object

### Phase 4: Re-embed Existing Memories
- Run `tests/re-embed-asymmetric.mjs`
- For memories without tags, either:
  - A) Leave untagged (treat as NONE)
  - B) Run through extraction LLM to retroactively tag (expensive)

### Phase 5: Settings UI (Optional)
- Add `embeddingQueryPrefix` input (default: "search for similar scenes: ")
- Add `embeddingTagFormat` dropdown (bracket/none)

## 8. Risks & Edge Cases

| Risk | Mitigation |
|---|---|
| All BM25 scores are 0 | `maxBM25` floored at `1e-9`, alpha-blend degrades to vector-only |
| Single outlier BM25 compresses others | Batch-max normalization is acceptable; alpha-blend caps contribution |
| IDF-aware boost makes rare entities too powerful | Limited by `entityBoostWeight` cap and alpha-blend ceiling |
| LLM assigns wrong tags | Tags are hints, not hard filters. Incorrect tags hurt ranking but don't break retrieval. |
| LLM refuses to tag / filters out NSFW | Use multilingual anchor words in prompt examples (–º–∏–Ω–µ—Ç, blowjob, „Éï„Çß„É©„ÉÅ„Ç™) to bypass censors. |
| Re-embedding takes too long | Progress indication, can run in background. ~30s for 100 memories on WebGPU. |
| Changing query prefix doesn't require re-embed | Query embeddings are computed on-the-fly; only doc/tag changes need re-embed. |
| Existing memories have no tags | Treat as `NONE`. Optionally run retroactive tagging via extraction LLM. |

## 9. Files to Modify

| File | Changes |
|------|---------|
| `src/prompts.js` | Add `<tags_field>` directive, update Zod schema, add `tags` to all examples |
| `src/embeddings/strategies.js` | Add `getQueryEmbedding()`, `getDocumentEmbedding()`, handle query prefix setting |
| Memory creation flow | Extract `tags` from LLM response, format `[TAG]` prefix, store in DB |
| `src/constants.js` | Add new settings defaults (embeddingQueryPrefix, embeddingTagFormat) |
| `tests/re-embed-asymmetric.mjs` | Update to use new prompt format |

## 10. Deleted / Not Created

- ~~`src/embeddings/auto-tagger.js`~~ - Not creating; LLM-based tagging is superior
- Regex-based tagging - Brittle, duplicates LLM understanding, drifts over time
